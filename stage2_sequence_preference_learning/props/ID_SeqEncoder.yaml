n_layers: 2
n_heads: 2
layer_norm_eps: 1e-12
initializer_range: 0.02
plm_text_size: 768
plm_image_size: 1000
plm_suffix: pth
hidden_act: 'gelu'
loss_type: 'CE'

hidden_size: 300
inner_size: 256
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5

seed: 2024
train_batch_size: 1024
gpu_id: 3
